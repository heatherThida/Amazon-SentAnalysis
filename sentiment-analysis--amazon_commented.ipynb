{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimental Analysis Amazon Review (Music Instrument) by Group 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk # for porter stemmer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy #for matrices\n",
    "import re\n",
    "import sklearn as skl\n",
    "import string\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the train and test data\n",
    "train = pd.read_json(\"data/music_200.json\", lines=True)\n",
    "test = pd.read_json(\"data/music_test_200.json\", lines=True)\n",
    "#display the top 5 preview\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the unwanted columns in our data\n",
    "train = train.drop(['asin', 'helpful', 'reviewTime', 'reviewerID', 'reviewerName', 'summary', 'unixReviewTime'], axis=1)\n",
    "test = test.drop(['asin', 'helpful', 'reviewTime', 'reviewerID', 'reviewerName', 'summary', 'unixReviewTime'], axis=1)\n",
    "#display what's left\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify the data based on review rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column called \"good\" if the overall rating is 5 and above and assign boolean value\n",
    "train2 = train.assign(good = lambda g: g.overall >= 5)\n",
    "#create a binary classfication 1 for all data that are good and 0 for that are not\n",
    "trainFinal = train.assign(good = train2['good'].apply(lambda g: 1 if g else 0))\n",
    "\n",
    "#display the first 10 data\n",
    "trainFinal.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to remove stop word and punctuations \n",
    "def rm_stopwords_punctuation(text):\n",
    "    text = text.lower()\n",
    "    with open(\"stopwords.json\") as stopword_file:\n",
    "        stopwords = json.load(stopword_file)\n",
    "        for word in stopwords:\n",
    "            if word in text:\n",
    "                # replace only complete words ('\\b' is a word boundary)\n",
    "                text = re.sub(r\"\\b{}\\b\".format(word), \"\", text)\n",
    "    # remove punctuation\n",
    "    for char in string.punctuation:\n",
    "        text = text.replace(char, \"\")\n",
    "    text = re.sub(r\"\\b[a-z]\\b\", \"\", text)\n",
    "    # remove whitespace\n",
    "    for char in string.punctuation:\n",
    "        text = text.replace(char, \"\")\n",
    "    text = ' '.join(text.split(None))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# funtion to remove stemmer using porterstem\n",
    "def stem(text):\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "    # stem each word individually, and concatenate\n",
    "    text = ' '.join([stemmer.stem(word) for word in text.split(None)])\n",
    "#     text = [stemmer.stem(word) for word in text.split(None)]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a method to apply 2 functions described above stopwords,punctuation and stemmer\n",
    "def process_text(text):\n",
    "    text = rm_stopwords_punctuation(text)\n",
    "    text = stem(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy train data to apply process_text method describe above\n",
    "trainNoProcess = trainFinal.copy()\n",
    "trainFinal['reviewText'] = trainFinal['reviewText'].apply(lambda t: process_text(t))\n",
    "\n",
    "#display the first 10 data\n",
    "trainFinal.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test data with no process vs processed and store in Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # just a test block to compare the result if we pick the overall rating greater or equal to 4\n",
    "# test2 = test.assign(good = lambda g: g.overall >= 4)\n",
    "# test2Final = test2.assign(good = test2['good'].apply(lambda g: 1 if g else 0))\n",
    "# test2NoProcess = test2Final.copy()\n",
    "# test2Final['reviewText'] = test2Final['reviewText'].apply(lambda t: process_text(t))\n",
    "# #test2NoProcess.head(10)\n",
    "# #test2Final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # store trained data as matrices Y contains binary classification and X contain text to process as list later\n",
    "# y, X = patsy.dmatrices(\"good ~ reviewText\", trainFinal, return_type=\"dataframe\")\n",
    "# y_test, X_test = patsy.dmatrices(\"good ~ reviewText\", test2Final, return_type=\"dataframe\")\n",
    "# y_noP, X_noP = patsy.dmatrices(\"good ~ reviewText\", trainNoProcess, return_type=\"dataframe\")\n",
    "# y_test_noP, X_test_noP = patsy.dmatrices(\"good ~ reviewText\", test2NoProcess, return_type=\"dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "#music_test = pd.read_json(\"data/reviews_Musical_Instruments_5.json\", lines=True)\n",
    "\n",
    "# read the different file, video game file as test \n",
    "vg_test = pd.read_json(\"data/reviews_Video_Games_5.json\", lines=True)\n",
    "\n",
    "\n",
    "# drop dummy columns that are not useful\n",
    "vg_test = vg_test.drop(['asin', 'helpful', 'reviewTime', 'reviewerID', 'reviewerName', 'summary', 'unixReviewTime'], axis=1)\n",
    "\n",
    "# show how long it takes in secs\n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time, \"seconds\")\n",
    "\n",
    "# for this much data \n",
    "vg_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat Classification (with no processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #start_time = time.time()\n",
    "\n",
    "# # repeat the same process, create classficiation \n",
    "# vg_test2 = vg_test.assign(good = lambda g: g.overall >= 5)\n",
    "# vg_testFinal = vg_test.assign(good = vg_test2['good'].apply(lambda g: 1 if g else 0))\n",
    "# vg_test_noP = vg_testFinal.copy()\n",
    "\n",
    "# # vg_testFinal['reviewText'] = vg_testFinal['reviewText'].apply(lambda t: process_text(t))\n",
    "\n",
    "# #put into matrices\n",
    "# y_vg_test, X_vg_test = patsy.dmatrices(\"good ~ reviewText\", vg_test_noP, return_type=\"dataframe\")\n",
    "# #elapsed_time = time.time() - start_time\n",
    "# #print(elapsed_time)\n",
    "# # show test data with no processing which has 10261 rows Ã— 3 columns\n",
    "# vg_test_noP.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # testing time efficiency and checking length of the data\n",
    "# start_time = time.time()\n",
    "# print(len(vg_test_noP))\n",
    "# #y_vg_test_noP, X_vg_test_noP = patsy.dmatrices(\"good ~ reviewText\", vg_test_noP, return_type=\"dataframe\")\n",
    "# elapsed_time = time.time() - start_time\n",
    "# print(len(y_vg_test_noP), len(X_vg_test_noP))\n",
    "# print(elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# logRegrModel = skl.linear_model.LogisticRegression()\n",
    "# logRegrModel = logRegrModel.fit(X, y['good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logRegrModel.score(X, y['good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logRegrModel.score(X_test, y_test['good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# logRegrModel_noP = skl.linear_model.LogisticRegression()\n",
    "# logRegrModel_noP = logRegrModel.fit(X_noP, y_noP['good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logRegrModel_noP.score(X_noP, y_noP['good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logRegrModel.score(X_test_noP, y_test_noP['good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logRegrModel.score(X_vg_test, y_vg_test['good'])\n",
    "# logRegrModel_noP.fit_transform(X_vg_test_noP, np.ravel(y_vg_test_noP))\n",
    "# logRegrModel_noP.score(X_vg_test_noP, y_vg_test_noP['good'])\n",
    "# logRegrModel_noP.score(X_noP, y_noP['good'])\n",
    "# y_vg_test_noP.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate between the column and transposed matrix of logistic regression model and store it as list\n",
    "# pd.DataFrame(list(zip(X_vg_test_noP.columns, np.transpose(logRegrModel_noP.coef_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# big_noP = skl.linear_model.LogisticRegression()\n",
    "# big_noP = logRegrModel.fit(X_vg_test_noP, y_vg_test_noP['good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big_noP.score(X_vg_test_noP, y_vg_test_noP['good'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cv = skl.feature_extraction.text.CountVectorizer(list(trainFinal['reviewText']))\n",
    "cv = skl.feature_extraction.text.CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFinal['reviewText'][199]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# counts = cv.fit_transform(list(trainFinal['reviewText']))\n",
    "counts = cv.fit_transform(list(vg_test_noP['reviewText']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_transformer = skl.feature_extraction.text.TfidfTransformer(use_idf=False).fit(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = tf_transformer.transform(counts)\n",
    "train_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = skl.feature_extraction.text.TfidfTransformer()\n",
    "train_tfidf = tfidf_transformer.fit_transform(counts)\n",
    "train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sklmodel = skl.linear_model.LogisticRegression()\n",
    "sklmodel = sklmodel.fit(train_tfidf, y_vg_test_noP['good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklmodel.score(train_tfidf, y_vg_test_noP['good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
